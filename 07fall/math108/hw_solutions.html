<html><head>
<link rel=stylesheet type="text/css" href="/handout.css" />
<style type="text/css"><!--
u {
  color: red;
  font-weight: bold;
  text-decoration: none;
}
i {
  color: blue;
  font-style: normal;
  font-weight: bold;
}
h2 { border-top: 1px solid black; }
--></style>

<title>MATH 108 Fall 2007 Homework Solutions, Trinity Western University</title>
</head><body>

<h1><a href="http://twu.seanho.com/07fall/math108/">MATH 108 Fall 2007</a>
Homework Solutions</h1>

<p>
These solutions are provided by the publisher of the textbook and are not for
redistribution or copying beyond this semester.

<p>
<table class="schedule">

<tr><th>HW# / Date</th><th>Page#</th><th>Question</td><th>Answers</th></tr>

<tr class="R"><th><a name="1">HW1 13 Sep</a></th>
	<td>p.  11	</td><td>#	2.3	</td><td>
(a): Number of leaves; categorical; a single plant; 25<br>
(b): Number of seizures; categorical; a single patient; 20
</td></tr>
<tr><td></td><td>p.  24	</td><td>#	2.5	</td><td>
(dotplot)
</td></tr>
<tr><td></td><td>p.  24	</td><td>#	2.6	</td><td>
(multiple ways to bin the histogram)
</td></tr>
<tr><td></td><td>p.  30	</td><td>#	2.20	</td><td>
mean = 3.492 lb, median = 3.36 lb.
</td></tr>
<tr><td></td><td>p.  30	</td><td>#	2.22	</td><td>
mean = 3.389 lb, median = 3.335 lb.
</td></tr>
<tr><td></td><td>p.  30	</td><td>#	2.28	</td><td>
mean approx 45, median approx 49 (median bigger than mean)
</td></tr>
<tr><td></td><td>p.  30	</td><td>#	2.29	</td><td>
approx 35%.
</td></tr>
<tr><td></td><td>p.  38	</td><td>#	2.33	</td><td>
(boxplot for men generally lower, although median and max are higher
than for women)
</td></tr>
<tr><td></td><td>p.  38	</td><td>#	2.36	</td><td>
(b): centered at 25, min near 12, max near 36.
</td></tr>
<tr><td></td><td>p.  48	</td><td>#	2.45	</td><td>
mean = -12.44 mmHg, std dev = 17.6 mmHg.
</td></tr>
<tr><td></td><td>p.  66	</td><td>#	2.69	</td><td>
(a) mean = 0.19, std dev = 4.22. <br>
(b) median = 1.0. <br>
(c) mean = 1.44, std dev = 2.08, median = 1.25.
median is resistant (robust); mean/stddev are not.
</td></tr>
<tr><td></td><td>p.  66	</td><td>#	2.78	</td><td>
The low volume distribution is symmetric, centered at 20, with a minimum of 0
and a maximum of 40.  The high volume distribution is shifted down from the low
volume distribution, with a median of about 18 and a maximum of 30, which is
the third quartile for the low volume distribution.  Thus, one-fourth of the
low volume hospitals have mortality rates greater than the highest mortality
rate among high volume hospitals.
</td></tr>

<tr class="R"><th><a name="2">HW2 20 Sep</a></th>
	<td>p.  77	</td><td>#	3.1	</td><td>
(point is that human judgment doesn't yield very random samples)
</td></tr>
<tr><td></td><td>p.  83	</td><td>#	3.5	</td><td>
(a) 51%.  (b) 94%.  (c) 46%.  (d) 54%
</td></tr>
<tr><td></td><td>p.  87	</td><td>#	3.6	</td><td>
(a) 0.3025.  (b) 0.7975.
</td></tr>
<tr><td></td><td>p.  87	</td><td>#	3.9	</td><td>
(a) test positive: (0.10)(0.98) + (0.90)(0.01) = 10.7%<br>
(b) 5.85%
</td></tr>
<tr><td></td><td>p.  87	</td><td>#	3.11	</td><td>
(a) (0.10)(0.92) + (0.90)(0.06) = 14.6%<br>
(b) 0.092/0.146 = 63%
</td></tr>
<tr><td></td><td>p.  92	</td><td>#	3.13	</td><td>
		(a) 1016/6549 = .1551<br>
		(b) 2480/6549 = .3787<br>
		(c) (1016 + 2480 - 526)/6549 = 2970/6549 = .4535<br>
		(d) 526/6549 = .0803 <br>
</td></tr>
<tr><td></td><td>p.  92	</td><td>#	3.14	</td><td>
Not independent: if smoking status of husband were independent of smoking
status of wife, then the probability that in a couple both husband and wife
would smoke would be (.30)(.20) = .06, rather than .08.  Note that Pr{husband
and wife both smoke} = Pr{husband smokes}Pr{wife smokes|husband smokes}.  If
smoking status of husband were independent of smoking status of wife, then we
would have Pr{husband and wife both smoke} = Pr{husband smokes}Pr{wife smokes}
= (.30)(.20) = .06.  But Pr{husband and wife both smoke} = .08, not .06
</td></tr>
<tr><td></td><td>p.  96	</td><td>#	3.16	</td><td>
		(a) Pr{20 &lt; Y &lt; 30} = .41 + .21 = .62<br>
		(b) .41 + .21 + .03 = .65<br> 
		(c) .01 + .34 = .35
</td></tr>
<tr><td></td><td>p.  96	</td><td>#	3.17	</td><td>
		(a) (.35)(.35) = .1225 <br>
		(b) (.35)(.24) = .084 <br>
		(c) (.35)(.24) + (.24)(.35) = .168
</td></tr>
<tr><td></td><td>p. 102	</td><td>#	3.21	</td><td>
		(a) .189 + .027 = .216 <br>
		(b) .343 + .441 + .189 = .973 
</td></tr>
<tr><td></td><td>p. 102	</td><td>#	3.22	</td><td>
(0)(.343) + (1)(.441) + (2)(.189) + (3)(.027) = .9
</td></tr>
<tr><td></td><td>p. 102	</td><td>#	3.23	</td><td>
The variance is (0 - .9)&sup2;(.343) + (1 - .9)&sup2; (.441) + (2 - .9)&sup2; (.189) + (3 - .9)&sup2; (.027) = .63 <br>Thus, the standard deviation is 0.794.
</td></tr>
<tr><td></td><td>p. 117	</td><td>#	3.38	</td><td>
		(a) (0.10)&sup2; = 0.01 <br>
		(b) (2)(.1)(.9) = 0.18 
</td></tr>
<tr><td></td><td>p. 117	</td><td>#	3.46	</td><td>
(a) .66 (b) .21 (c) .38 
</td></tr>

<tr class="R"><th><a name="3">HW3 27 Sep</a></th>
	<td>p.  92	</td><td>#	3.12	</td><td>
(a) 1213/6549 = .1852 <br>
(b) 247/2115 = .1168 <br>
(c) No; the probability of a person being a smoker depends on whether or not the person has high income, since the answers to (a) and (b) differ.  
</td></tr>
<tr><td></td><td>p. 131	</td><td>#	4.2	</td><td>
(a) 1.28 (b) 1.28 
</td></tr>
<tr><td></td><td>p. 131	</td><td>#	4.3	</td><td>
(a) For y = 1500, 
 z = (y - µ)/s  = (1500 - 1400)/100  = 1.00.
 From Table 3, the area is .8413 or 84.13%.<br>
(b) For y = 1325, 
 z = (y - µ)/s  = (1325 - 1400)/100  = -.75.
 From Table 3, the area below 1325 is .2266.
 From part (a), the area below 1500 is .8413.
 Thus, the percentage between 1325 and 1500 is
 .8413 - .2266 = .6147 or 61.47%.<br>
(c) For y = 1325, 
 z = (y - µ)/s  = (1325 - 1400)/100  = -.75.
 From Table 3, the area below 1325 is .2266.
 Thus, the percentage with Y &ge; 1325 is
 1 - .2266 = .7734 or 77.34%.  <br>
(d) For y = 1475, 
 z = 0.75.
 From Table 3, the area below 1475 is .7734.
 Thus, the percentage with Y &ge; 1475 is
 1 - .7734 = .2266 or 22.66%.  <br>
(e) For y = 1600, 
 z = 2.00.
 From Table 3, the area below 1600 is .9772.
 In part (d) we found that the area below 1475 is .7734.
 Thus, the percentage with 1475 &le; Y &le; 1600 is
 .9772 - .7734 = .2038 or 20.38%.<br>
(f) For y = 1200, 
 z = -2.00.
 From Table 3, the area below 1200 is .0228.
 In part (c) we found that the area below 1325 is .2266.
 Thus, the percentage with 1200 &le; Y &le; 1325 is
 .2266 - .0028 = .2038 or 20.38%.	 
</td></tr>
<tr><td></td><td>p. 131	</td><td>#	4.4	</td><td>
(a) For y = 1325, 
 z = -0.75.
 From Table 3, the area is .2266 or 22.66%.<br>
(b) This is the same as part (e) of Exercise 4.3.  
 For y = 1600, 
 z = 2.00.
 From Table 3, the area below 1600 is .9772.
 For y = 1475, 
 z = 0.75.
 From Table 3, the area below 1475 is .7734.
 Thus, the percentage with 1475 &le; Y &le; 1600 is
 .9772 - .7734 = .2038 or 20.38%.	 
</td></tr>
<tr><td></td><td>p. 131	</td><td>#	4.12	</td><td>
(a) µ = 5,000,000 which means that 
 s = (.008)(5,000,000) = 40,000.
 For y = 4,900,000, 
 z = (4900000 - 5000000)/40000  = -2.5.
 For y = 5,100,000, 
 z = (5100000 - 5000000)/40000  = 2.5.
 Thus, Pr{4,900,000 &lt; Y &lt; 5,100,000}
 = Pr{-2.5 &lt; Z &lt; 2.5} 
 = .9938 - .0062 = .9876.<br>
(b) Pr{.98µ &lt; Y &lt; 1.02µ} = Pr{(.98µ - µ)/.008µ  &lt; (Y - µ)/s  &lt; (1.02µ - µ)/.008µ }
= Pr{-2.5 &lt; Z &lt; 2.5} = .9938 - .0062 = .9876<br>
(c) A specimen reading Y differs from the correct value by 2% or more if it does not satisfy .98µ &lt; Y &lt; 1.02µ.  Using the answer from part (b), this probability is 
1 - .9876 = .0124 or 1.24%.  
</td></tr>
<tr><td></td><td>p. 141	</td><td>#	4.21	</td><td>
(a) At the low end of the distribution the normal probability plot is fairly straight, indicating that the data agree with what one would expect from a normal distribution.  Thus, the times for the fastest riders are roughly equal to the times one would expect if the data came from a truly normal distribution.<br>
(b) At the high end of the distribution the normal probability plot bends upward, indicating that the times are greater than what one would expect from a normal distribution.  Thus, the times for the slowest riders are worse than the times one would expect.
</td></tr>
<tr><td></td><td>p. 144	</td><td>#	4.22	</td><td>
(a) Pr{Y &ge; 40} = Pr{Y &gt; 39.5} =~ Pr{Z &gt; (39.5 - 38.5)/2.9 } = Pr{Z &gt; .34} 
= 1 - .6331 = .3669 or 36.69%.<br>
(b) Pr{Y = 40} = Pr{39.5 &lt; Y &lt; 40.5} =~ Pr{(39.5 - 38.5)/2.9  &lt; Z &lt; (40.5 - 38.5)/2.9 }.  This is the probability that Z is between .34 and .69, which is .7549 - .6331 = .1218 or 12.18%.<br> 
(c) Pr{35 &le; Y &le; 40} = Pr{34.5 &lt; Y &lt; 40.5} =~ Pr{(34.5 - 38.5)/2.9  &lt; Z &lt; (40.5 - 38.5)/2.9 }.  This is the probability that Z is between -1.38 and .69, which is .7549 - .0838 = .6711 or 67.11%.  
</td></tr>
<tr><td></td><td>p. 146	</td><td>#	4.36	</td><td>
By symmetry of the normal curve,
µ = (61.2 + 67.4)/2  = 64.3 inches.
In Table 3, the area closest to .9 is .8997, which corresponds to z = 1.28.  Therefore, we have
1.28 = (67.4 - 64.3)/s, which yields &sigma; = (67.4 - 64.3)/1.28 = 2.4 inches.  
</td></tr>
<tr><td></td><td>p. 146	</td><td>#	4.40	</td><td>
µ = 145; &sigma; = 22.  The distribution of readings is a normal distribution with mean µ (the true concentration) and standard deviation &sigma;.  A reading of 40 or more is considered "unusually high."  Suppose that µ = 35 and &sigma; = 4.<br>
For y = 40, z = (40 - 35)/4  = 1.25.
  From Table 3, the area below 1.25 is .8944, which means that the area above 1.25 is 1 - .8944 = .1056.  Thus, 
  Pr{specimen is flagged as "unusually high} = .1056.  
</td></tr>
<tr><td></td><td>p. 146	</td><td>#	4.41	</td><td>
		(a) 1 - .5948 = .4052 <br>
		(b) 1 - .8729 = .1271 <br>
		(c) .7549 - .4168 = .3381 
</td></tr>
<tr><td></td><td>p. 146	</td><td>#	4.42	</td><td>
0.2546
</td></tr>
<tr><td></td><td>p. 146	</td><td>#	4.43	</td><td>
Pr{0 &lt; Y &lt; 15} = .7549 - .2546 = .5003.  Thus we expect (400)(.5003), or about 200 observations to fall between 0 and 15.
</td></tr>
<tr><td></td><td>p. 146	</td><td>#	4.44	</td><td>
The IQR is 14.74 - (-.14) = 14.88.  An outlier on the high end of the distribution is any point greater than 14.74 + (1.5)(14.88) = 37.06.
</td></tr>
<tr><td></td><td>p. 164	</td><td>#	5.15	</td><td>
(a) In the population, µ = 176 and &sigma; = 30.
 For y = 186, z = (186 - 176)/30  = .33.
 From Table 3, the area below .33 is .6293.
 For y = 166, z = -0.33.
 From Table 3, the area below -.33 is .3707.
 Thus, the percentage with 166 &le; y &le; 186
 is .6293 - .3707 = .2586, or 25.86%.	<br> 
(b) We are concerned with the sampling distribution of &Yuml; for n = 9.  From Theorem 5.1, the mean of the sampling distribution of &Yuml; is 176, the standard deviation is
&sigma;<sub>&Yuml;</sub> = &sigma;/&radic;n = 30/&radic;9 = 10,
and the shape of the distribution is normal because the population distribution is normal (part 3a of Theorem 5.1).<br> 
 For &yuml; = 186, 
 z = (186 - 176)/10  = 1.00.
 From Table 3, the area below 1.00 is .8413.
 For &yuml; = 166, 
 z = (166 - 176)/10  = -1.00.
 From Table 3, the area below -1.00 is .1587.
 Thus, the percentage with 166 &le; &yuml; &le; 186
  is .8413 - .1587 = .6826, or 68.26%.	<br>
(c) The probability of an event can be interpreted as the long-run relative frequency of occurrence of the event (Section 3.3).  Thus, the question in part (c) is just a rephrasing of the question in part (b).  It follows from part (b) that 
		Pr{166 &le; &yuml; &le; 186} = .6826.  

</td></tr>
<tr class="R"><th><a name="4">HW4 11 Oct</a></th>
	<td>p.  164	</td><td>#	5.16	</td><td>
(a) µ = 3000; &sigma; = 400.<br>
The event E occurs if &Yuml;  is between 2900 and 3100.  We are concerned with the sampling distribution of &Yuml;  for n = 15.  From Theorem 5.1, the mean of the sampling distribution of &Yuml;  is 
µ<sub>&Yuml;</sub> = µ = 3000, the standard deviation is &sigma;<sub>&Yuml;</sub> = &sigma;/&radic;n = 400/&radic;15  = 103.3,
and the shape of the distribution is normal because the population distribution is normal (part 3a of Theorem 5.1).<br>
For &yuml;  = 3100, z = (&yuml; - µ<sub>&Yuml;</sub>)/&sigma;<sub>&Yuml;</sub> = (3100 - 3000)/103.3  = 0.97.
 From Table 3, the area below 0.97 is 0.8340.
 For &yuml;  = 2900, z = -0.97.  From Table 3, the area below -0.97 is 0.1660.<br>
 Thus, Pr{2900 &le; &Yuml;  &le; 3100} = Pr{E} = 0.8340 - 0.1660 = 0.6680.	
 <br>
(b) n = 60; &sigma;<sub>&Yuml;</sub>  = 400/&radic;60  = 51.64
z = ±100/51.64  = ±1.94; Table 3 gives .9738 and .0262, so Pr{E} = .9738 - .0262 = .9476.<br>
(c) As n increases, Pr{E} increases.
</td></tr>
<tr><td></td><td>p. 164	</td><td>#	5.17	</td><td>
&sigma;<sub>&Yuml;</sub>  = 400/&radic;15  = 103.3<br>
(a) z = (2900 - 2800)/103.3  = .97.  From Table 3, the area below .97 is .8340.<br>
z = (2700 - 2800)/103.3  = -.97.  From Table 3, the area below -.97 is .1660.<br>
Thus, Pr{E} = .8340 - .1660 = .6680<br>
(b) z = (2700 - 2600)/103.3  = .97.  From Table 3, the area below .97 is .8340.<br>
z = (2500 - 2600)/103.3  = -.97.  From Table 3, the area below -.97 is .1660.<br>
Thus, Pr{E} = .8340 - .1660 = .6680<br>
(c) For fixed n and &sigma;, Pr{E} does not depend on µ.  
</td></tr>
<tr><td></td><td>p. 164	</td><td>#	5.20	</td><td>
(a) In the population, 65.68% of the fish are between 51 and 60 mm long.  To find the probability that four randomly chosen fish are all between 51 and 60 mm long,<br>
Pr{all 4 are between 51 and 60} = (0.6568)<sup>4</sup> =~ 0.1861.<br> 
(b) The mean length of four randomly chosen fish is &Yuml; .  Thus, we are concerned with the sampling distribution of &Yuml;  for a sample of size n = 4 from a population with µ = 54 and &sigma; = 4.5.  From Theorem 5.1, the mean of the sampling distribution of &Yuml;  is 
µ<sub>&Yuml;</sub> = µ = 54, the standard deviation is &sigma;<sub>&Yuml;</sub> = &sigma;/&radic;n  = 4.5/&radic;4  = 2.25,
and the shape of the distribution is normal because the population distribution is normal (part 3a of Theorem 5.1).<br>
For &yuml;  = 60, z = (&yuml; - µ<sub>&Yuml;</sub>)/&sigma;<sub>&Yuml;</sub> = (60 - 54)/2.25  = 2.67.<br>
From Table 3, the area below 2.67 is .9962.<br>
For &yuml;  = 51, z = (&yuml; - µ<sub>&Yuml;</sub>)/&sigma;<sub>&Yuml;</sub> = (51 - 54)/2.25  = -1.33.<br>
From Table 3, the area below -1.33 is .0918.<br>
 Thus, Pr{51 = &Yuml;  = 60} = .9962 - .0918 = .9044.	
</td></tr>
<tr><td></td><td>p. 164	</td><td>#	5.21	</td><td>
Let E1 be the event that all four fish are between 51 and 60 mm long and let E2 be the event that &Yuml; is between 51 and 60 mm long.  If E1 occurs, then E2 must also occur -- the mean of four numbers, each of which is between 51 and 60, must be between 51 and 60 -- but E2 can occur without E1 occurring.  Thus, in the long run, E2 will happen more often than E1, which shows that Pr{E2} &gt; Pr{E1}.
</td></tr>
<tr><td></td><td>p. 164	</td><td>#	5.24	</td><td>
(a) µ<sub>&Yuml;</sub>  = µ = 41.5.<br>
(b) &sigma;<sub>&Yuml;</sub>  = 4.7/&radic;4 = 2.35<br> 
</td></tr>
<tr><td></td><td>p. 164	</td><td>#	5.25	</td><td>
(a) Because the sample size of 2 is small, we would expect the histogram of the sample means to be skewed to the right, as is the histrogram of the data.  However, the histogram of the sample means will be somewhat symmetric (more so than the histogram of the data).
(b) Because the sample size of 25 is fairly large, we would expect the histogram to have a bell shape.  
</td></tr>
<tr><td></td><td>p. 164	</td><td>#	5.26	</td><td>
The sample mean is just an individual observation when n=1.  Thus, the histogram of the sample means will be the same as the histogram of the data (and therefore be skewed to the right).
</td></tr>
<tr><td></td><td>p. 164	</td><td>#	5.27	</td><td>
No.  The histogram shows the distribution of observations in the sample.  Such a distribution would look more like the population distribution for n = 400 than for n = 100, and the population distribution is apparently rather skewed.  The Central Limit Theorem applies to the sampling distribution of &Yuml;, which is not what is shown in the histogram.
</td></tr>
<tr><td></td><td>p. 177	</td><td>#	5.50	</td><td>
µ = 1,200; &sigma; = 35.<br>
For Pr{1175 &le; Y &le; 1225}, 
z = (1225 - 1200)/35  = .71; Table 3 gives .7611.<br>
z = (1175 - 1200)/35  = -.71; Table 3 gives .2389.<br>
.7611 - .2389 = .5222.<br>
For Pr{1175 &le; &Yuml; &le; 1225}, &sigma;<sub>&Yuml;</sub>  = &sigma;/&radic;n  = 35/&radic;6  = 14.29.<br>
z = (1225 - 1200)/14.29  = 1.75; Table 3 gives .9599.<br>
z = (1175 - 1200)14.29  = -1.75; Table 3 gives .0401.<br>
.9599 - .0401 = .9198.<br>
Comparison: .9189 &gt; .5222; this shows that the mean of 6 counts is more precise, in that it is more likely to be near the correct value (1200) than is a single count.  
</td></tr>
<tr><td></td><td>p. 177	</td><td>#	5.51	</td><td>
&mu; = 8.3; &sigma; = 1.7.<br>
If the total weight of 10 mice is 90 gm, then their mean weight is 90/10  = 9.0 gm.
Thus, we wish to find the percentage of litters for which &yuml;  = 9.0 gm.  
We are concerned with the sampling distribution of &Yuml;   for n = 10.  
From Theorem 5.1, the mean of the sampling distribution of &Yuml;  is &mu;<sub>&Yuml;</sub> = &mu; = 8.3,
the standard deviation is &sigma;<sub>&Yuml;</sub>  = &sigma;/&radic;n  = 1.7/&radic;10  = .538,
and the shape of the distribution is normal because the population distribution is normal (part 3a of Theorem 5.1).<br>
For &yuml;  = 9.0, z = (&yuml; - &mu;<sub>&Yuml;</sub>)/&sigma;<sub>&Yuml;</sub> = (9.0 - 8.3)/0.538  = 1.30.<br>
From Table 3, the area below 1.30 is .9032.<br>
Thus, the percentage with &yuml;  &ge; 9.0 is 1 - .9032 = .0968, or 9.68%.	
</td></tr>
<tr><td></td><td>p. 177	</td><td>#	5.52	</td><td>
Two possible factors are: (a) environmental and genetic differences between litters; (b) competition between mice in a litter.
</td></tr>
<tr><td></td><td>p. 185	</td><td>#	6.4 	</td><td>
3.06/&radic;86  = .33 mm
</td></tr>
<tr><td></td><td>p. 185	</td><td>#	6.5 	</td><td>
(a) We would predict the SD of the new measurements to be about 3 mm because this is our estimate (based on Exercise 6.4) of the population SD.<br>
(b) We would expect the SE of the new measurements to be 3/&radic;500  &cong; .13 mm.  
</td></tr>
<tr class="R"><th><a name="5">HW5 18 Oct</a></th>
	<td>p.  185	</td><td>#	6.7 	</td><td>
(a) the SE; (b) the SD; (c) the SE 
</td></tr>
<tr><td></td><td>p. 194	</td><td>#	6.10	</td><td>
(a) &yuml;  = 31.720 mg; s = 8.729 mg; n = 5.<br>
The standard error of the mean is SE<sub>&yuml;</sub> = s/&radic;n  = 8.729/&radic;5  = 3.904 mg.<br>
(b) The degrees of freedom are n - 1 = 5 - 1 = 4.  The critical value is t<sub>.05</sub> = 2.132.
The 90% confidence interval for &mu; is &yuml;  &plusmn; t<sub>.05</sub>(s/&radic;n) =
31.720 &plusmn; 2.132(8.729/&radic;5 ) = (23.4, 40.0)  or  23.4 &lt; &mu; &lt; 40.0 mg.  
</td></tr>
<tr><td></td><td>p. 194	</td><td>#	6.11	</td><td>
(a) The degrees of freedom are n - 1 = 5 - 1 = 4.  The critical value is t<sub>.025</sub> = 2.776.<br>
The 95% confidence interval for &mu; is &yuml;  &plusmn; t<sub>.025</sub>(s/&radic;n) = 
31.720 &plusmn; 2.776(8.729/&radic;5) = (20.9, 42.5)  or  20.9 &lt; &mu; &lt; 42.5 mg.<br> 
(b) We are 95% confident that the mean thymus gland weight in the population of chick embryos is between 20.9 and 42.5 mg.  
</td></tr>
<tr><td></td><td>p. 194	</td><td>#	6.12	</td><td>
(a) &yuml;  = 28.7; s = 4.5898; SE = 4.5898/&radic;6  = 1.87 &micro;g/ml.<br>
28.7 &plusmn; (2.571)(1.9)  = (23.8,33.6)  or  23.8 &lt; &mu; &lt; 33.6 &micro;g/ml.<br>
(b) &mu; = mean blood serum concentration of Gentamicin (1.5 hours after injection of 10 mg/kg body weight) in healthy three-year-old female Suffolk sheep.<br>
(c) No.  The "95%" refers to the percentage (in a meta-experiment) of confidence intervals that would contain &mu;.  Since the width of a confidence interval depends on n, the percentage of observations contained in the confidence interval also depends on n, and would be very small if n were large.
</td></tr>
<tr><td></td><td>p. 194	</td><td>#	6.13	</td><td>
(a) This statement is false.  The confidence interval allows us to make an inference concerning the mean of the entire population.  We know that 59.77 &lt; &yuml;  &lt; 61.09.<br>
(b) This statement is true.  (See part (a).)
</td></tr>
<tr><td></td><td>p. 194	</td><td>#	6.14	</td><td>
This statement is false.  The confidence interval concerns the mean of the population.  It does not tell us where individual data points lie.
</td></tr>
<tr><td></td><td>p. 194	</td><td>#	6.20	</td><td>
&yuml;  = 1.20; s = .14; n = 50.<br>
The degrees of freedom are 50 - 1 = 49.  From Table 4 with df = 50 (the df value closest to 49) we find that t<sub>.05</sub> = 1.676.
The 90% confidence interval for &mu; is &yuml;  &plusmn; t<sub>.05</sub> (s/&radic;n) =
1.20 &plusmn; 1.676(.14/&radic;50 ) = (1.17,1.23)  or  1.17 &lt; &mu; &lt; 1.23 mm.  
</td></tr>
<tr><td></td><td>p. 194	</td><td>#	6.21	</td><td>
We are 95% confident that the mean Bayley Index of prematurely born infants who receive intravenous-feeding solutions is between 93.8 and 102.1.  (Although the center of the interval is 97.95, which is less than the general population average of 100, the interval extends above 100, so we cannot be sure that &mu; is less than 100.)
</td></tr>
<tr><td></td><td>p. 199	</td><td>#	6.28	</td><td>
We use the inequality (Guessed SD)/&radic;n &le; (Desired SE).<br>
In this case, the desired SE is 3 mg/dl and the guessed SD is 40 mg/dl.  Thus, the inequality is
40/&radic;n &le; 3  or  40/3 &le; &radic;n  which means that n &ge; 177.8, so a sample of 
n = 178 men is needed.  
</td></tr>
<tr><td></td><td>p. 204	</td><td>#	6.31	</td><td>
The fact that the mean is less than the SD casts doubt on the condition that the population is normal, for the following reason.  In a normal population, about 15% of the observations fall more than one SD below the mean, whereas this sample cannot have any observations that far below the mean because &yuml; - s is negative and the observed variable (serum SGOT) cannot be negative.
</td></tr>
<tr><td></td><td>p. 204	</td><td>#	6.32	</td><td>
(a) There were 36 cells, but only seven guinea pigs, so there is a hierarchical structure in the data, which suggests that the observations are not independent.<br>
(b) The distribution has two or perhaps three modes, which may reflect the hierarchical structure in the data (that is, different modes may represent different animals or groups of animals.)
</td></tr>
<tr><td></td><td>p. 204	</td><td>#	6.33	</td><td>
The outlier (1,060) suggests that the population distribution is not normal but rather is skewed to the right or long-tailed.  Because the sample size is small, Student's t method is not appropriate if the population is not normal.
</td></tr>
<tr><td></td><td>p. 216	</td><td>#	6.56	</td><td>
(a) 28.86 &plusmn; (2.576)(4.24/&radic;1353) = (28.56,29.16)  or  28.56 &lt; &mu; &lt; 29.16 days.<br>
(b) The confidence interval is not consistent with the hypothesis because 29.5 is not in the interval.  
</td></tr>
<tr><td></td><td>p. 216	</td><td>#	6.57	</td><td>
(a) The mean of all reported cycles is smaller because the women with shorter cycles had more cycles during the fixed time period, and therefore contributed more observations to the data.  
(b) It would not be valid because the 5412 observations are not independent -- there is a hierarchical structure in the data.  
</td></tr>
<tr><td></td><td>p. 216	</td><td>#	6.60	</td><td>
The confidence interval should be (6.2,7.4).  The confidence interval is an interval estimate of the population mean.  The data only take on integer values, but the mean of the population need not be an integer (and probably is not).
</td></tr>
<tr><td></td><td>p. 216	</td><td>#	6.61	</td><td>
(a) .42/&radic;84  = .04583<br>
(c) 4.36 &plusmn; (1.984)(.04583) = (4.269,4.451)  or  4.269 &lt; &mu; &lt; 4.451 mEq/l.<br> 
(d) We are 95% confident that the average serum potassium concentration in the blood of all healthy women is between 4.269 mEq/l and 4.451 mEq/l.  
</td></tr>
<tr><td></td><td>p. 216	</td><td>#	6.62	</td><td>
No.  The confidence interval would be much too narrow; only a minority of healthy women would fall within the confidence interval.  Instead, the interval &yuml;  ± 2SD would be a reasonable choice for reference limits.
</td></tr>
<tr><td></td><td>p. 216	</td><td>#	6.63	</td><td>
(a) We would predict the SD of the new measurements to be about .42 mEq/l, because this is our best estimate (based on Exercise 6.54) of the population SD.<br>
(b) .42/&radic;200  = .030 mEq/l.  
</td></tr>
<tr><td></td><td>p. 216	</td><td>#	6.68	</td><td>
(a) &yuml;  = 145.3; s = 12.87; SE = 12.87/&radic;1139  = .381.<br>
The confidence interval is 145.3 ± (1.96)(.381) or (144.55,146.05) or 144.55 &lt; µ &lt; 146.05 g/l.<br> 
(b)  No.  The obtained 95% confidence interval is a confidence interval for the population mean hemoglobin level.  It does not give limits for individual data points.  
(c)  No.  See the answer to part (b).  
</td></tr>
<tr><td></td><td>p. 226	</td><td>#	7.4 	</td><td>
SE<sub>1</sub> = 6.5/&radic;5 = 2.907; SE<sub>2</sub> = 8.4/&radic;7 = 3.175.<br>
&radic;(2.907&sup2; + 3.175&sup2;)  = 4.30.  
</td></tr>
<tr><td></td><td>p. 226	</td><td>#	7.5 	</td><td>
SE<sub>1</sub> = 6.5/&radic;10 = 2.055; SE<sub>2</sub> = 8.4/&radic;14 = 2.245.<br>
&radic;(2.055&sup2; + 2.245&sup2;)  = 3.04
</td></tr>
<tr><td></td><td>p. 226	</td><td>#	7.9 	</td><td>
&radic;( 5.5&sup2; + 8.6&sup2; ) = 10.2.
</td></tr>
<tr class="R"><th><a name="6">HW6 25 Oct</a></th>
	<td>p.  226	</td><td>#	7.8 	</td><td>
SE<sub>1</sub> = .400/&radic;9 = .133; SE<sub>2</sub> = .220/&radic;6 = .090.<br>
&radic;(0.133&sup2; + 0.090&sup2;)  = 0.16
</td></tr>
<tr><td></td><td>p. 231	</td><td>#	7.10 	</td><td>
Let 1 denote males and let 2 denote females.<br>
&yuml;<sub>1</sub> = 45.8; SE<sub>1</sub> = 2.8/&radic;489  = .127.<br>
&yuml;<sub>2</sub> = 40.6; SE<sub>2</sub> = 2.9/&radic;469  = .134.<br>
The standard error of the difference is SE<sub>(y1 - y2)</sub>  = .1272 + .1342  = .185.<br>
The critical value t<sub>.025</sub> is determined from Student's t distribution with df = 950.
Using df = 1000 (the nearest value given in Table 4), we find that t(1000)<sub>.025</sub> = 1.962.<br>
The 95% confidence interval is (&yuml;<sub>1</sub> - &yuml;<sub>2</sub>) ± t<sub>.025</sub> SE<sub>(y1 - y2)</sub>
= (45.8 - 40.6) &plusmn; (1.962)(.185).  <br>
So the confidence interval is (4.84,5.56)  or  4.84 &lt; µ1 - µ2 &lt; 5.56.  
</td></tr>
<tr><td></td><td>p. 231	</td><td>#	7.12 	</td><td>
(a) Let 1 denote biofeedback and let 2 denote control.<br>
SE<sub>(y1 - y2)</sub>  = &radic;( 1.34&sup2; + 1.30&sup2; )  = 1.867.<br>
(13.8 - 4.0) &plusmn; (1.977)(1.867)		(using df = 140)<br>
(6.1,13.5)  or  6.1 &lt; µ1 - µ2 &lt; 13.5 mm Hg.<br>
(b) We are 95% confident that the population mean reduction in systolic blood pressure for those who receive training for eight weeks (µ1) is larger than that for others (µ2) by an amount that might be as small as 6.1 mm Hg or as large as 13.5 mm Hg.  
</td></tr>
<tr><td></td><td>p. 231	</td><td>#	7.13 	</td><td>
No.  The confidence interval found in Exercise 7.11 is valid even if the distributions are not normal, because the sample sizes are large.
</td></tr>
<tr><td></td><td>p. 244	</td><td>#	7.25 	</td><td>
(a) .085 &lt; .10, which means that the P-value is less than &alpha;.  Thus, we reject H<sub>0</sub>.<br>
(b) .065 &gt; .05, which means that the P-value is greater than &alpha;.  Thus, we do not reject H<sub>0</sub>.<br> 
(c) Table 4 gives t(19)<sub>.005</sub> = 2.861 and t(19)<sub>.0005</sub> = 3.883,
so .001 &lt; P &lt; .01.  Since P &lt; &alpha;, we reject H<sub>0</sub>.<br>
(d) Table 4 gives t(12)<sub>.05</sub> = 1.782 and t(12)<sub>.04</sub> = 1.912,
so .08 &lt; P &lt; .10.  Since P &gt; &alpha;, we do not reject H<sub>0</sub>.  
</td></tr>
<tr><td></td><td>p. 244	</td><td>#	7.29 	</td><td>
(a) The null and alternative hypotheses are H<sub>0</sub>: &mu;<sub>1</sub> = &mu;<sub>2</sub>;
H<sub>A</sub>: &mu;<sub>1</sub> &ne; &mu;<sub>2</sub>,
where 1 denotes heart disease and 2 denotes control.  These hypotheses may be stated as
<ul>
<li>H<sub>0</sub>: Mean serotonin concentration is the same in heart patients and in controls 
<li>H<sub>A</sub>: Mean serotonin concentration is not the same in heart patients and in controls 
</ul>
The test statistic is t<sub>s</sub> = (3840 - 5310)/1064  = -1.38.<br>
From Table 4 with df = 14, we find the critical values t(.10) = 1.345 and t(.05) = 1.761.
Thus, the P-value is bracketed as .10 &lt; P &lt; .20.<br>
Since the P-value is greater than &alpha; (.05), H<sub>0</sub> is not rejected.  <br>
(b) There is insufficient evidence (.10 &lt; P &lt; .20) to conclude that serotonin levels are different in heart patients than in controls.<br> 
(c)  SE<sub>(y1 - y2)</sub>  = &radic;( 850&sup2; + 640&sup2; ) = 1064.  
</td></tr>
<tr><td></td><td>p. 244	</td><td>#	7.31 	</td><td>
(a) H<sub>0</sub>: mean thymus weight is the same at 14 and 15 days (µ<sub>1</sub> = µ<sub>2</sub>)<br>
H<sub>A</sub>: mean thymus weight is not the same at 14 and 15 days (µ<sub>1</sub> &ne; µ<sub>2</sub>)<br>
SE<sub>(y1 - y2)</sub>  = &radic;(8.73&sup2;/5 + 7.19&sup2;/5 ) = 5.06<br> 
t = (31.72 - 29.22)/5.06 = .49.  df = n<sub>1</sub> + n<sub>2</sub> - 2 = 8.
(Formula (7.1) gives df = 7.7.)  Table 4 gives t<sub>.20</sub> = .889; thus P &gt; .40,
so we do not reject H<sub>0</sub>.  There is insufficient evidence (P &gt; .40) to conclude that 
mean thymus weight is different at 14 and 15 days.<br>
(b) According to the P-value found in part (a), the fact that y<sub>1</sub> is greater than y<sub>2</sub> could easily be attributed to chance.  
</td></tr>
<tr><td></td><td>p. 244	</td><td>#	7.33 	</td><td>
(a) H<sub>0</sub>: Albumin and polygelatin are equally effective as plasma expanders (µ<sub>1</sub> = µ<sub>2</sub>)<br>
H<sub>A</sub>: Albumin and polygelatin are not equally effective as plasma expanders (µ<sub>1</sub> &ne; µ<sub>2</sub>)<br>
SE<sub>(y1 - y2)</sub>  = &radic;(60&sup2; + 30&sup2; ) = 67.08.<br>
ts = (490 - 240)/67.08 = 3.73. 	 	df = n<sub>1</sub> + n<sub>2</sub> - 2 = 37 and t(40)<sub>.0005</sub> = 3.551.<br>
Thus, P &lt; .001, so we reject H<sub>0</sub>.<br>
(b) There is sufficient evidence (P &lt; .001) to conclude that albumin is more effective than polygelatin as a plasma expander. 
</td></tr>
<tr><td></td><td>p. 244	</td><td>#	7.36 	</td><td>
(a) True.  We would reject H<sub>0</sub> because the P-value is less than &alpha;.<br>
(b)  False. We do not reject H<sub>0</sub> because the P-value is greater than &alpha;.<br>
(c) False.  The P-value is the probability, under H<sub>0</sub>, of getting a result as extreme as, or more extreme than, the result that was actually observed. 
</td></tr>
<tr><td></td><td>p. 244	</td><td>#	7.37 	</td><td>
(a) H<sub>0</sub>: mean number of colonies is the same for control and soap (µ<sub>1</sub> = µ<sub>2</sub>)<br>
H<sub>A</sub>: mean number of colonies is not the same for control and soap (µ<sub>1</sub> &ne; µ<sub>2</sub>)<br>
SE<sub>(y1 - y2)</sub>  = 10.21.  ts = (41.8 - 32.4)/10.21 = .92.  Using Table 4 with df=10 we have t<sub>.20</sub> = .879 and t<sub>.10</sub> = 1.372.  Thus .20 &lt; P &lt; .40, so we do not reject H<sub>0</sub>.<br>
(b) There is insufficient evidence (.20 &lt; P &lt; .40) to conclude that the mean number of colonies differs for control and soap. 
</td></tr>
<tr><td></td><td>p. 265	</td><td>#	7.49 	</td><td>
(a)  No.  With df = 23, Table 4 gives t<sub>.10</sub> = 1.319 and t<sub>.05</sub> = 1.714.  Thus, .05 &lt; P &lt; .10.  Since P &gt; &alpha;, we do not reject H<sub>0</sub>.<br>
(b)  Yes.  With df = 5, Table 4 gives t<sub>.04</sub> = 2.191 and t<sub>.03</sub> = 2.422.  Thus, .03 &lt; P&lt; .04.  Since P &lt; &alpha;, we reject H<sub>0</sub>.<br>
(c)  No.  Because ts &gt; 0, the data do not deviate from H<sub>0</sub> in the direction specified by H<sub>A</sub>.  Thus, P &gt; .50 and we do not reject H<sub>0</sub>.<br>
(d)  Yes.  With df = 27, Table 4 gives t<sub>.005</sub> = 2.771 and t<sub>.0005</sub> = 3.690.  Thus, .0005 &lt; P &lt; .005.  Since P &lt; &alpha;, we reject H<sub>0</sub>. 
</td></tr>
<tr><td></td><td>p. 265	</td><td>#	7.51 	</td><td>
Let 1 denote experimental (to be hypnotized) and 2 denote control.<br>
SE<sub>(y1 - y2)</sub>  = &radic;( .621&sup2;/8 + .652&sup2;/8 ) = .3183.<br>
t = (6.169 - 5.291)/.3183 = 2.76.
With df = n<sub>1</sub> + n<sub>2</sub> - 2 = 14 (Formula (7.1) yields df = 13.97),
Table 4 gives t<sub>.01</sub> = 2.624 and t<sub>.005</sub> = 2.977.<br>
(a) H<sub>0</sub>: Mean ventilation is the same in the "to be hypnotized" condition and in the "control" condition (µ<sub>1</sub> = µ<sub>2</sub>)<br>
H<sub>A</sub>: Mean ventilation is different in the "to be hypnotized" condition than in the "control" condition (µ<sub>1</sub> &ne; µ<sub>2</sub>)<br>
H<sub>0</sub> is rejected.  There is sufficient evidence (.01 &lt; P &lt; .02) to conclude that mean ventilation is higher in the "to be hypnotized" condition than in the "control" condition.<br>
(b) H<sub>0</sub>: Mean ventilation is the same in the "to be hypnotized" condition and in the "control" condition (µ<sub>1</sub> = µ<sub>2</sub>)<br>
H<sub>A</sub>: Mean ventilation is higher in the "to be hypnotized" condition than in the "control" condition ( µ<sub>1</sub> &gt; µ<sub>2</sub>)<br>
H<sub>0</sub> is rejected.  There is sufficient evidence (.005 &lt; P &lt; .01) to conclude that mean ventilation is higher in the "to be hypnotized" condition than in the "control" condition.<br>
(c) The nondirectional alternative (part (a)) is more appropriate.  According to the narrative, the researchers formulated the directional alternative in part (b) after they had seen the data.  Thus, it would not be legitimate for them (or us) to use a directional alternative. 
</td></tr>
<tr><td></td><td>p. 265	</td><td>#	7.54 	</td><td>
(a) The null and alternative hypotheses are H<sub>0</sub>: &mu;<sub>1</sub> = &mu;<sub>2</sub>;
and H<sub>A</sub>: &mu;<sub>1</sub> &gt; &mu;<sub>2</sub>, where 1 denotes drug and 2 denotes placebo.
These hypotheses may be stated as<ul>
	<li>H<sub>0</sub>: The drug is not effective
	<li>H<sub>A</sub>: The drug is effective</ul>
To check the directionality of the data, we note that &yuml;<sub>1</sub> &gt; &yuml;<sub>2</sub>.
Thus, the data do deviate from H<sub>0</sub> in the direction (&mu;<sub>1</sub> &gt; &mu;<sub>2</sub>) specified by H<sub>A</sub>.
We proceed to calculate the test statistic.<br>
The standard error of the difference is SE<sub>(y1 - y2)</sub>  
= &radic;( 12.05&sup2;/25 + 13.78&sup2;/25 ) = 3.66.<br>
The test statistic is t = (31.96 - 25.32)/3.66  = 1.81.<br>
From Table 4 with df = 25 + 25 -2 = 48 (Formula (7.1) yields df = 47.2),
we find the critical values t<sub>.04</sub> = 1.787 and t<sub>.03</sub> = 1.924.<br>
Thus, the P-value is bracketed as .03 &lt; P &lt; .04.
Since the P-value is less than &alpha; (.05), we reject H<sub>0</sub>.<br>
There is sufficient evidence (.03 &lt; P &lt; .04) to conclude that the drug is effective at 
increasing pain relief.<br>
(b) The only change in the calculations from part (a) would be that the one-tailed area would be doubled if the alternative were nondirectional.  Thus, the p-value would be between .06 and .08 and at &alpha; = .05 we would not reject H<sub>0</sub>. 
</td></tr>
<tr><td></td><td>p. 272	</td><td>#	7.58 	</td><td>
The lack of a statistically significant difference in therapeutic responses does not show that the two medications are equally effective.  (Such evidence could be obtained from either a confidence interval or an analysis of the power of the test.) 
</td></tr>
<tr><td></td><td>p. 272	</td><td>#	7.62 	</td><td>
The mean difference in serum concentration of uric acid is &mu;<sub>1</sub> - &mu;<sub>2</sub>, where 1 denotes men and 2 denotes women.<br>
We construct a 95% confidence interval for &mu;<sub>1</sub> - &mu;<sub>2</sub>.<br>
SE<sub>(&yuml;<sub>1</sub> - &yuml;<sub>2</sub>)</sub>  = &radic;( .058&sup2;/530 + .051&sup2;/420 )  = .00354.<br>
The critical value t<sub>.025</sub> is found from Student's t distribution with df = n<sub>1</sub> + n<sub>2</sub> - 2 = 948.
(Formula (7.1) gives df = 937.8.)<br>
From Table 4, we find t(1000)<sub>.025</sub> = 1.962.  The 95% confidence interval is
(.354 - .263) &plusmn; (1.962)(.00354) = (.0841,.0979)  or  .0841 &lt; &mu;<sub>1</sub> - &mu;<sub>2</sub> &lt; .0979 mmol/l.<br>
All values in the confidence interval are greater than .08 mmol/l.
Therefore, according to the confidence interval the data indicate that the difference is "clinically important." 
</td></tr>
<tr><td></td><td>p. 272	</td><td>#	7.63 	</td><td>
		SE<sub>(&yuml;<sub>1</sub> - &yuml;<sub>2</sub>)</sub>  = &radic;( .058&sup2;/53 + .051&sup2;/42 )  = .0112.<br>
Confidence interval is (.354 - .263) &plusmn; (1.984)(.0112) (using df = 100),
or (.069,.113),  or  .069 &lt; &mu;<sub>1</sub> - &mu;<sub>2</sub> &lt; .113 mmol/l.<br>
The difference could be greater than or less than .08 mmol/l, so the data do not
indicate whether the difference is "clinically important." 
</td></tr>
<tr><td></td><td>p. 305	</td><td>#	7.104	</td><td>
(a)  False.  The confidence interval includes zero, so we are not confident
that 1 and 2 are different.<br> 
(b)  True.  This is what a confidence interval tells us.<br>
(c)  False.  We know that the difference of sample means is exactly 6.9.<br> 
(d)  False.  The confidence interval is used to make an inference about the
difference between  &yuml;<sub>1</sub> and &yuml;<sub>2</sub>; it does not tell us about individual 
data points (such as the length of hospitalization for a nitric oxide infant).
<tr><td></td><td>p. 305	</td><td>#	7.105	</td><td>
False.  The 95% confidence interval includes zero, which means that the P-value
for a nondirectional test is greater than .05.  Thus, we would not reject H0 at
the .05 significance level.
</td></tr>
<tr><td></td><td>p. 305	</td><td>#	7.109	</td><td>
(a) Let 1 denote andro and let 2 denote control.<ul> 
  <li>H<sub>0</sub>: Andro has no effect (&mu;<sub>1</sub> = &mu;<sub>2</sub>)
  <li>H<sub>A</sub>: Andro has an effect (&mu;<sub>1</sub> &ne; &mu;<sub>2</sub>)</ul>
  SE = <i>5.94</i>.  t = (14.4 - 20.0)/5.94 = <i>-.94</i>.
  With df=16, Table 4 gives t<sub>0.20</sub> = 0.865 and t<sub>0.10</sub> = 1.337,
  so <i>.20 &lt; p &lt; .40</i>.  (Using a computer, we get p = .359.)
  Thus, we <i>fail to reject H<sub>0</sub></i>.  There is insufficient evidence 
  (.20 &lt; p &lt; .40) to conclude that andro affects lat pulldown strength.
<br>(b) <ul>
  <li>H<sub>0</sub>: Andro has no effect (&mu;<sub>1</sub> = &mu;<sub>2</sub>)
  <li>H<sub>A</sub>: Andro has a positive effect (&mu;<sub>1</sub> &gt; &mu;<sub>2</sub>)</ul>
  The one-tailed p-value is between .10 and .20; this is still larger than
  the level of significance.
  Thus, we still <i>fail to reject H<sub>0</sub></i>.
  There is insufficient evidence (.10 &lt; p &lt; .20) to conclude that andro 
  increases lat pulldown strength.
</td></tr>
<tr class="R"><th><a name="7">HW7  1 Nov</a></th>
	<td>p.  296	</td><td>#	7.79	</td><td>
(a) The null and alternative hypotheses are <ul>
  <li>H<sub>0</sub>: Toluene has no effect on dopamine in rat striatum
  <li>H<sub>A</sub>: Toluene has some effect on dopamine in rat striatum.
  </ul>
  Let 1 denote toluene and let 2 denote control.
  For the K<sub>1</sub> count, we note that there are four Y2's less than the first Y1;
  there are five Y2's less than the second Y1; there are five Y2's less than
  the third Y1; and there are six Y2's less than the fourth, fifth, and sixth
  Y1.
  <ul><li>  Thus, K<sub>1</sub> = 4 + 5 + 5 + 6 + 6 + 6 = <i>32</i>.
  Similarly, K<sub>2</sub> = 0 + 0 + 0 + 0 + 1 + 3 = <i>4.</i></ul>
  To check the counts, we verify that 
  K<sub>1</sub> + K<sub>2</sub> = 32 + 4 = 36 = (6)(6) = (n1)(n2).
  In the non-directional case, the Wilcoxon-Mann-Whitney test statistic is the larger of the
  two counts K<sub>1</sub> and K<sub>2</sub>; thus U<sub>s</sub> = 32.
  Looking in Table 6 under n = 6 and n' =
  6, we find that for a nondirectional alternative, the .05 entry is 31 and the
  .02 entry is 33.  Thus, the P-value is bracketed as <i>.02 &lt; P &lt; .05.</i>
  At significance level &alpha; = .05, we <i>reject H0</i>, since P &lt; .05.
  We note that K1 is larger than K2, which indicates a tendency for the Y1's 
  to be larger than the Y2's.  Thus, there is sufficient evidence 
  (.02 &lt; P &lt; .05) to conclude
  that toluene increases dopamine in rat striatum.<br>
(b) When conducting a nondirectional test, we must check directionality.  In 
  this case, we note that K1 is larger than K2, which indicates a tendency 
  for the Y1's to be larger than the Y2's, which is what the directional 
  alternative predicts.  We proceed as in part (a), except that we use the 
  "directional" tail probabilities.  Thus, <i>.01 &lt; P &lt; .025</i>.
  We <i>reject H0</i> and conclude that there is sufficient evidence 
  (.01 &lt; P &lt; .025) to conclude that toluene increases dopamine in rat striatum.
</td></tr>
<tr><td></td><td>p. 296	</td><td>#	7.82 	</td><td>
		(a) <ul><li>H<sub>0</sub>: There is no sex difference in preening behavior
			<li>H<sub>A</sub>: There is a sex difference in preening behavior
</ul>
For n = n' = 15, the largest critical value is 189, which is under the .001 heading
for a nondirectional alternative.  It follows that P &lt; .001, so H<sub>0</sub> is rejected.
There is sufficient evidence (P &lt; .001) to conclude that females tend to preen longer than males.<br>
(b) <ul><li>H<sub>0</sub>: There is no sex difference in preening behavior (&mu;<sub>1</sub> = &mu;<sub>2</sub>)
	<li>H<sub>A</sub>: There is a sex difference in preening behavior (&mu;<sub>1</sub> &ne; &mu;<sub>2</sub>)
</ul>
ts = (2.127 - 4.093)/.7933 = -2.48.  With df = n<sub>1</sub> + n<sub>2</sub> - 2 = 28,
Table 4 gives t<sub>.01</sub> = 2.467 and t<sub>.005</sub> = 2.763, so that .01 &lt; P &lt; .02.
Formula (7.1) yields df = 15.1 and the conservative approach of df = min{n<sub>1</sub> - 1, n<sub>2</sub> - 1} gives df = 14.
For either of these df values we get .02 &lt; P &lt; .04.  In any case, H<sub>0</sub> is not rejected, since P &gt; .01.
There is sufficient evidence to conclude that there is a sex difference in preening behavior.<br>
(c) Both tests require independent, random samples.  The condition required for the
t test but not for the Wilcoxon-Mann-Whitney test is that the population distributions are normal.
The frequency distribution for the females is highly skewed, due to the two large observations of 10.7 and 11.7.
This casts doubt on the normality condition.<br>
(d)  K<sub>1</sub> = 0 + 0 + 0 + 0 + 0 + .5 + 1 + 1.5 + 1.5 + 2 + 2 + 3.5 + 5 + 8.5 + 10 = 35.5<br>
K<sub>2</sub> = 5.5 + 8 + 3(11.5) + 3(13) + 13.5 + 14 + 5(15) = 189.5<br>
where 1 denotes male and 2 denotes female. 
</td></tr>
<tr><td></td><td>p. 296	</td><td>#	7.84 	</td><td>
Let 1 denote joggers and let 2 denote fitness program entrants.<ul>
	<li> H<sub>0</sub>: There is no difference in resting blood concentration of HBE between joggers fitness program entrants
	<li> H<sub>A</sub>: There is a difference in resting blood concentration of HBE between joggers fitness program entrants
</ul>
K1 = 93.5, K2 = 71.5, Us = 93.5.  With n = 15 and n' = 11, 108 is under the .20 heading for a nondirectional alternative
and is the smallest entry listed.  Thus, P &gt; .20 and H<sub>0</sub> is not rejected.  There is insufficient evidence (P &gt; .20)
to conclude that there is a difference in resting blood concentration of HBE between joggers fitness program entrants. 
</td></tr>
<tr><td></td><td>p. 300	</td><td>#	7.86 	</td><td>
The null and alternative hypotheses are <ul>
   <li>H0: Mean platelet calcium is the same in people with high blood 
   pressure as in people with normal blood pressure (mu1 = mu2)
   <li>HA: Mean platelet calcium is different in people with high blood 
   pressure than in people with normal blood pressure (mu1 /= mu2).</ul>
   The standard error of the difference is SE = <i>5.399</i>.<br>
   The test statistic is t = (168.2 - 107.9)/5.399  = <i>11.2</i>. <br>
   From Table 4 with df = 45 + 38 -2 = 81  80, we find the critical 
   value t(.0005) = 3.416.  The tail area is doubled for the nondirectional 
   test.  Thus, the P-value is bracketed as <i>P &lt; .001</i>.<br>
   (Formula (7.1) yields df = 67.5, but the P-value is still bracketed as 
   P &lt; .001.)<br>
   Since the P-value is less than alpha (.01), we <i>reject H0</i>.  There is
   sufficient evidence (P &lt; .001) to conclude that mean platelet calcium
   is higher in people with high blood pressure than in people with normal
   blood pressure.
</td></tr>
<tr><td></td><td>p. 300	</td><td>#	7.87 	</td><td>
  The critical value t(.025) is found from Student's t distribution with df 
  given by Formula (7.1) as df = 67.5 &cong; 70.<br>
  Table 4 gives t(70)(.025) = <i>1.994</i>.  The 95% confidence interval is
  <i>(49.5, 71.1)</i>.<br>
  Alternatively, we could use df = 45 + 38 -2 = 81 &cong; 80, in which case the
  critical value is t(80).025 = 1.990.  This gives an interval of 
  (49.6, 71.0).
</td></tr>
<tr><td></td><td>p. 300	</td><td>#	7.88 	</td><td>
  <i>No</i>; the t test is valid because the sample sizes are rather large
</td></tr>
<tr><td></td><td>p. 300	</td><td>#	7.98 	</td><td>
(a)  Two of the patients contributed two observations each to the data set.
  Thus, there is hierarchical structure, so the t test is <i>not appropriate</i>.<br>
(b)  No.  The Wilcoxon-Mann-Whitney test, like the t test, requires that the
  observations within a sample be independent of each other, so the
  Wilcoxon-Mann-Whitney test is <i>not appropriate</i>.
</td></tr>
<tr><td></td><td>p. 300	</td><td>#	7.103	</td><td>
(a) Let 1 denote amphetamine and let 2 denote control.<ul>
  <li>H<sub>0</sub>: Amphetamine is not related to water consumption
  (&mu;<sub>1</sub> = &mu;<sub>2</sub>)
  <li>H<sub>A</sub>: Amphetamine is associated with decreased water consumption 
  (&mu;<sub>1</sub> &lt; &mu;<sub>2</sub>)</ul>
  SE of the mean difference is <i>18.82</i>.<br>
  t = (129.375 - 156)/18.82 = <i>-1.415</i>.<br>
  With df = n1 + n2 - 2 = 6 (Formula (7.1) yields df = 5.9),
  Table 4 gives t(.20) = 0.906 and t(.10) = 1.440, so <i>.10 &lt; P &lt; .20.</i><br>
  (Using a computer, we get P = .104.)  Thus, we <i>fail to reject H0</i>.<br>
  There is insufficient evidence (.10 &lt; P &lt; .20) to conclude that 
  amphetamine is associated with decreased water consumption.<br>
(b)<ul><li>H0: Amphetamine is not related to water consumption
  <li>HA: Amphetamine is associated with decreased water consumption</ul>
  <i>K1 =  4, K2 = 12, Us = 12</i>; the data deviate from H0 in the direction 
  specified by HA.  With n = 4, n' = 4, and a directional alternative, the 
  smallest entry is 13, under the .10 heading.  Thus, <i>P &gt; .10</i> and 
  we <i>fail to reject H0</i>.  There is insufficient evidence 
  (P &gt; .10) to conclude that 
  amphetamine is associated with decreased water consumption.  
</td></tr>
<tr><td></td><td>p. 300	</td><td>#	7.106	</td><td>
(a)  False.  The P-value for a test is the probability of getting data at least as extreme as those obtained, if H<sub>0</sub> is true; it is not the probability that the null hypothesis is true.  <br>
(b)  True.  The P-value for a test is the probability of getting data at least as extreme as those obtained, if H<sub>0</sub> is true, which is what this statement says.  <br>
(c)  False.  The probability that H<sub>0</sub> is rejected depends on the power of the test, which is not known.  (If H<sub>0</sub> is true -- and we don't know if it is true or not -- and a new study is done that uses &alpha; = .04, then there is a 4% probability that H<sub>0</sub> will be rejected.)
</td></tr>
<tr><td></td><td>p. 356	</td><td>#	9.3  	</td><td>
Let 1 denote control and let 2 denote progesterone.<ul>
	<li>H<sub>0</sub>: Progesterone has no effect on cAMP (&mu;<sub>1</sub> = &mu;<sub>2</sub>)
	<li>H<sub>A</sub>: Progesterone has some effect on cAMP (&mu;<sub>1</sub> &ne; &mu;<sub>2</sub>)
</ul>
The standard error is
SE<sub>(&yuml;<sub>1</sub> - &yuml;<sub>2</sub>)</sub>  = SE<sub>d</sub>  = s<sub>d</sub>/&radic;n<sub>d</sub>  = .40/&radic;4  = .20.<br>
The test statistic is
ts = ( &yuml;<sub>1</sub> - &yuml;<sub>2</sub> ) / SE<sub>(&yuml;<sub>1</sub> - &yuml;<sub>2</sub>)</sub>   = d / SE<sub>d</sub>  = .68/.20  = 3.4.  <br>
To bracket the P-value, we consult Table 4 with df = 4 - 1 = 3.
Table 4 gives t<sub>.025</sub> = 3.182 and t<sub>.02</sub> = 3.482.
Thus, the P-value is bracketed as .04 &lt; P &lt; .05.<br>
At significance level &alpha; = .10, we reject H0 if P &lt; .10.  Since .04 &lt; P &lt; .05, we reject H<sub>0</sub>.
There is sufficient evidence (.04 &lt; P &lt; .05) to conclude that progesterone decreases cAMP under these conditions.  
</td></tr>
<tr><td></td><td>p. 356	</td><td>#	9.6  	</td><td>
The data provide fairly strong evidence (p = .03) that desipramine is more effective than clomipramine in reducing the compulsion to pull one's hair.
</td></tr>
<tr><td></td><td>p. 356	</td><td>#	9.9  	</td><td>
There is no single correct answer.  Any data set with Y1 and Y2 varying, but d not varying, is correct; for example:
<table border="1"><tr><th>Y<sub>1</sub></th><th>Y<sub>2</sub></th><th>d</th></tr>
	<tr><td>5</td><td>3</td><td>2</td></tr>
	<tr><td>6</td><td>4</td><td>2</td></tr>
	<tr><td>3</td><td>1</td><td>2</td></tr>
	<tr><td>4</td><td>2</td><td>2</td></tr>
	<tr><td>5</td><td>3</td><td>2</td></tr>
</table>
</td></tr>
<tr><td></td><td>p. 370	</td><td>#	9.16 	</td><td>
Let p denote the probability that oral conjugated estrogen will decrease PAI-1
  level.<ul>
  <li>H0: Oral conjugated estrogen has no effect on PAI-1 level (p = .5)
  <li>HA: Oral conjugated estrogen has an effect on PAI-1 level (p &ne; .5)</ul>
  N+ = 8, N- = 22, Bs = <i>22</i>.  With nd = 30, 22 falls under the .02 
  heading (for a nondirectional alternative) in Table 7.  Thus, 
  <i>.01 &lt; P &lt; .02</i> and we <i>reject H0</i>.  There is sufficient 
  evidence (.01 &lt; P &lt; .02) to conclude that oral conjugated estrogen 
  tends to decrease PAI-1 level.  
</td></tr>
<tr><td></td><td>p. 370	</td><td>#	9.19 	</td><td>
Let p denote the probability that a patient will have fewer minor seizures with
  valproate then with placebo.<ul>
  <li>H0: Valproate is not effective against minor seizures (p = .5)
  <li>HA: Valproate is effective against minor seizures (p &gt; .5) </ul>
  N+ = 14, N- = 5, Bs = <i>14</i>; the data deviate from H0 in the direction
  specified by HA.  Eliminating the pair with d = 0, we refer to Table 7 
  with nd = 19.  The only entry of 14 falls under the .05 heading (for a 
  directional alternative).  Thus, <i>.025 &lt; P &lt; .05</i> and we 
  <i>reject H0</i>.  There is sufficient evidence (.025 &lt; P &lt; .05) 
  to conclude that valproate is effective against minor seizures.  
</td></tr>
<tr><td></td><td>p. 385	</td><td>#	9.38 	</td><td>
(a) SE = 1.2/&radic;15 = <i>0.3098</i>.  df=14.
  Confidence interval is -1 &plusmn; (2.145)(0.3098) = <i>(-1.66, -0.34)</i><br>
(b) SE = &radic;(1.66&sup2;/15 + 2.37&sup2;/15) = <i>0.7471</i>.
  Confidence interval is -1 &plusmn; (2.145)(0.7471) = <i>(-2.60, 0.60)</i>.
  This interval is much wider than the one constructed in (a).
</td></tr>
<tr><td></td><td>p. 385	</td><td>#	9.39 	</td><td>
<ul><li>H0: The before and after means are the same (mu1 = mu2)
  <li>HA: The before and after means are different (mu1 &ne; mu2)</ul>
  SE = 1.2/&radic;15 = <i>.3098</i>.  t = -1/.3098 = <i>-3.23</i>.
  With df = 14, Table 4 gives t(.005) = 2.977 and t(.0005) = 4.140; thus,
  <i>.001 &lt; P &lt; .01.</i> We <i>reject H0</i>; there is strong evidence 
  (.001 &lt; P &lt; .01) of a before and after difference.  
</td></tr>
<tr><td></td><td>p. 385	</td><td>#	9.40a	</td><td>
Let p denote the probability that a before count is higher than the
  corresponding after count.<ul>
  <li>H0: p = .5
  <li>HA: p &ne; .5</ul>
  N+ = 2, N- = 10, Bs = <i>10</i>.  Looking under nd = 12 in Table 7, we see 
  that <i>.02 &lt; P &lt; .05</i>.  There is sufficient evidence 
  (.02 &lt; P &lt; .05) to conclude that the after count tends to be higher
  than the before count.
</td></tr>
<tr><td></td><td>p. 385	</td><td>#	9.41 	</td><td>
The scatterplot shows a positive relationship between before and after counts.  The pairing removes the variability between cats from the analysis and is, therefore, effective.
</td></tr>
<tr><td></td><td>p. 385	</td><td>#	9.49 	</td><td>
The null and alternative hypotheses are<ul>
  <li>H0: Caffeine has no effect on RER (mu1 = mu2)
  <li>HA: Caffeine has some effect on RER (mu1 &ne; mu2)</ul>
  S = 5.59/&radic;9 = <i>1.86</i>. t = 7.33/1.86 = <i>3.94</i>.
  To bracket the P-value, we consult Table 4 with df = 9 - 1 = 8.  Table 4
  gives t(.005) = 3.355 and t(.0005) = 5.041.  Thus, the P-value for the
  nondirectional test is bracketed as <i>.001 &lt; P &lt; .01</i>.
  At significance level alpha = .05, we <i>reject H0</i>.
  There is sufficient evidence (.001 &lt; P &lt; .01) to conclude that 
  caffeine tends to decrease RER under these conditions.  
</td></tr>
<tr><td></td><td>p. 385	</td><td>#	9.51 	</td><td>
Let p denote the probability that RER for a subject is higher after taking
  placebo than after taking caffeine.<ul>
  <li>H0: RER is not affected by caffeine (p = .5)
  <li>HA: RER is affected by caffeine (p &ne; .5)</ul>
  N+ = 9, N- = 0, Bs = <i>9</i>.  Looking under nd = 9 in Table 7, we see that 
  the rightmost column with a critical value less than or equal to 9 is the 
  column headed .01 (for a nondirectional alternative), and the next column is
  headed .002.  Therefore, <i>.002 &lt; P &lt; .01</i>.  There is sufficient 
  evidence (.002 &lt; P &lt; .01) to conclude that caffeine tends to 
  decrease RER under these conditions.  
</td></tr>
<tr><td></td><td>p. 385	</td><td>#	9.55 	</td><td>
(a) By using matched pairs we eliminate the variability that is associated with
  the variables used to create the pairs (age, sex, etc.).  This provides for
  greater precision and more power in the test.<br>
(b) It may be that the pairing variables (age, sex, etc.) are unrelated
  to blood pressure.  If this is the case, then the pairing accomplishes
  nothing, but it reduces the number of degrees of freedom, and therefore
  the power, of the test.
</td></tr>
<tr><td></td><td>p. 385	</td><td>#	9.57 	</td><td>
A normal probability plot of the data shows that the normality condition is not met.
However, a sign test can be conducted.  Let p denote the probability that urinary protein 
excretion will go down after plasmapheresis.  <ul>
	<li> H<sub>0</sub>: Plasmapheresis affects urinary protein excretion (p = .5)
	<li> H<sub>A</sub>: Plasmapheresis does not affect urinary protein excretion (p &ne; .5)
</ul>
N+ = 6, N- = 0, Bs = 6.  From Table 7, .02 &lt; p &lt; .05 (for a two-sided test).<br>
The exact p-value is (2)(.56) = .03125.  Thus, there is evidence (p = .03125) to conclude that
urinary protein excretion tends to go down after plasmapheresis.<br>
Note: Another approach would be to transform the data and then conduct a t test in the transformed scale.  For example, taking the reciprocal of each difference yields a fairly symmetric distribution; a t test then gives t = 5.4 and p = .003.
</td></tr>
<tr class="R"><th><a name="8">HW8 15 Nov</a></th>
	<td>p.  ---	</td><td>#	10.---	</td><td>

</td></tr>
<tr><td></td><td>p. ---	</td><td>#	10.---	</td><td>

</td></tr></table>
</body></html>
